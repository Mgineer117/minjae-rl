{"loss/critic_loss": 10.784008979797363, "loss/actor_loss": -1.907348590179936e-08, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 2.944485664367676, "_timestamp": 1716694012.556589, "eval/episode_reward": 25.0, "eval/episode_reward_std": 1.4142135623730951, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 25.0, "eval/episode_length_std": 1.4142135623730951, "update/env_step": 0.0, "_runtime": 10.268196821212769, "_step": 0}