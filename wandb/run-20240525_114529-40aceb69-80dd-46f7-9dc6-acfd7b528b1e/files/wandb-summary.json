{"loss/critic_loss": 2.850880569881863, "loss/actor_loss": 1.4055355787277222, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 0.38384419017367893, "_timestamp": 1716655565.7840724, "_runtime": 36.407689332962036, "_step": 48, "eval/episode_reward": 4.0, "eval/episode_reward_std": 0.0, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 4.0, "eval/episode_length_std": 0.0, "update/env_step": 39.0, "_wandb": {"runtime": 36}}