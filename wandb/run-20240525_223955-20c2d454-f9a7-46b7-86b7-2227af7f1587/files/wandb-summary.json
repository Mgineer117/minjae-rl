{"loss/critic_loss": 561.6650594075521, "loss/actor_loss": -6.993611467720484e-09, "train/stochastic_reward": 0.9203154643376669, "train/success": 0.0, "sample_time": 2.056365887324015, "_timestamp": 1716695374.6647842, "_runtime": 578.9594812393188, "_step": 172, "eval/episode_reward": 80.36817511574212, "eval/episode_reward_std": 2.525121776258085, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 76.33333333333333, "eval/episode_length_std": 2.6246692913372702, "update/env_step": 169.0}