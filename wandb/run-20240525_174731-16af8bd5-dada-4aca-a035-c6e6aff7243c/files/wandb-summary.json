{"loss/critic_loss": 704604.5625, "loss/actor_loss": 2.651214572324534e-07, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 4.96572470664978, "_timestamp": 1716677297.2845821, "eval/episode_reward": 40.0, "eval/episode_reward_std": 0.0, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 40.0, "eval/episode_length_std": 0.0, "update/env_step": 2.0, "_runtime": 45.96332025527954, "_step": 2}