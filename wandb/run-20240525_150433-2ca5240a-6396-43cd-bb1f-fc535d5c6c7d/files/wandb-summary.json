{"loss/critic_loss": 36.918212345668245, "loss/actor_loss": -3.4332275974538866e-08, "train/stochastic_reward": 0.7502691916057042, "train/success": 0.0, "sample_time": 1.5883948802947998, "_timestamp": 1716669740.9839084, "_runtime": 2267.6540203094482, "_step": 926, "eval/episode_reward": 13.919916530725573, "eval/episode_reward_std": 4.083758156943735, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 35.333333333333336, "eval/episode_length_std": 0.4714045207910317, "update/env_step": 919.0, "_wandb": {"runtime": 2269}}