[36mSaving config:
{
    "action_dim":	"1",
    "actor_hidden_dims":	[
        256,
        256
    ],
    "agent_type":	"InvertedPendulum",
    "algo_name":	"trpo",
    "critic_lr":	0.001,
    "data_num":	1000000,
    "device":	"cpu",
    "env_type":	"Gym",
    "episode_len":	1000,
    "episode_num":	2,
    "epoch":	2000,
    "eval_episodes":	3,
    "grad_norm":	false,
    "group":	"Gym-InvertedPendulum-seed-0",
    "hidden_dims":	[
        256,
        256
    ],
    "import_policy":	false,
    "logdir":	"log/trpo-88db-seed0/Gym-InvertedPendulum-seed-0",
    "max_action":	"3.0",
    "name":	"trpo-88db-seed0",
    "obs_shape":	[
        4
    ],
    "pklfile":	null,
    "project":	"data-collect",
    "rendering":	false,
    "seed":	0,
    "step_per_epoch":	1,
    "task":	"Gym-InvertedPendulum",
    "task_name":	null,
    "task_num":	3,
    "verbose":	true
}
Epoch:   0%|                                                                                        | 0/2000 [00:00<?, ?it/s]
  gym.logger.warn(
Epoch:   0%|                                                                              | 1/2000 [00:02<1:16:10,  2.29s/it]

Epoch:   1%|▍                                                                            | 11/2000 [00:25<1:18:02,  2.35s/it]

Epoch:   2%|█▏                                                                           | 32/2000 [01:13<1:13:57,  2.25s/it]

Epoch:   8%|█████▊                                                                      | 153/2000 [05:48<1:08:35,  2.23s/it]

Epoch:  14%|██████████▉                                                                 | 287/2000 [10:50<1:03:19,  2.22s/it]

Epoch:  16%|████████████▏                                                               | 320/2000 [12:04<1:02:37,  2.24s/it]

Epoch:  18%|█████████████▍                                                              | 353/2000 [13:18<1:00:03,  2.19s/it]
Traceback (most recent call last):
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data/trpo_collect.py", line 149, in <module>
    train()
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data/trpo_collect.py", line 145, in train
    policy_trainer.online_train(args.seed)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/../minjae-rl/rlkit/policy_trainer/mf_policy_trainer.py", line 137, in online_train
    batch, sample_time = self.sampler.collect_samples(self.policy, seed)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/../minjae-rl/rlkit/buffer/sampler.py", line 269, in collect_samples
    p.join()
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/multiprocessing/popen_fork.py", line 43, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt