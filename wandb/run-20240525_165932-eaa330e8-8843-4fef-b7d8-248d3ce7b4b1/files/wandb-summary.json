{"loss/critic_loss": 110.8858413696289, "loss/actor_loss": 0.0, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 1.0677635669708252, "_timestamp": 1716675267.5923233, "eval/episode_reward": 7.333333333333333, "eval/episode_reward_std": 3.299831645537222, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 7.333333333333333, "eval/episode_length_std": 3.299831645537222, "update/env_step": 393.0, "_runtime": 894.9876453876495, "_step": 393, "_wandb": {"runtime": 894}}