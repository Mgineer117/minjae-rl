{"loss/critic_loss": 11.670798015594482, "loss/actor_loss": -6.198883295560619e-10, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 1.1502203226089476, "_timestamp": 1716674359.0228093, "_runtime": 1568.5941743850708, "_step": 669, "eval/episode_reward": 12.0, "eval/episode_reward_std": 0.0, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 12.0, "eval/episode_length_std": 0.0, "update/env_step": 669.0, "_wandb": {"runtime": 1570}}