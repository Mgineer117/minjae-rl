{"loss/critic_loss": 119.95272572835286, "loss/actor_loss": 59.91726048787435, "train/stochastic_reward": 0.7161681652069092, "train/success": 0.0, "sample_time": 1.4754575888315837, "_timestamp": 1716672898.915817, "_runtime": 1337.8673620224, "_step": 602, "eval/episode_reward": 5.6340157731416065, "eval/episode_reward_std": 0.004778548046920327, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 29.0, "eval/episode_length_std": 0.0, "update/env_step": 599.0, "_wandb": {"runtime": 1334}}