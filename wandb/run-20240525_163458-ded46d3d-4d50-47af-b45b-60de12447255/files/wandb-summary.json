{"loss/critic_loss": 735412.359375, "loss/actor_loss": -9.405613177193572e-08, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 0.9647216200828552, "_timestamp": 1716675304.0845423, "_runtime": 2405.520529270172, "_step": 1283, "eval/episode_reward": 5.0, "eval/episode_reward_std": 0.0, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 5.0, "eval/episode_length_std": 0.0, "update/env_step": 1279.0, "_wandb": {"runtime": 2405}}