{"loss/critic_loss": 74.83428955078125, "loss/actor_loss": 37.3551025390625, "train/stochastic_reward": 0.5018029808998108, "train/success": 0.0, "sample_time": 4.056962490081787, "_timestamp": 1716655780.007864, "eval/episode_reward": 200.82919201476435, "eval/episode_reward_std": 0.18381338147218326, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 500.0, "eval/episode_length_std": 0.0, "update/env_step": 1.0, "_runtime": 46.53888297080994, "_step": 1, "_wandb": {"runtime": 47}}