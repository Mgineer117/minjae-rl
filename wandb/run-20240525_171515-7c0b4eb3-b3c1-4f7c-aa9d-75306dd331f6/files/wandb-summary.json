{"loss/critic_loss": 3.4341635704040527, "loss/actor_loss": -1.0013580187262505e-08, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 1.0831379890441895, "_timestamp": 1716675803.3540785, "eval/episode_reward": 3.0, "eval/episode_reward_std": 0.0, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 3.0, "eval/episode_length_std": 0.0, "update/env_step": 234.0, "_runtime": 487.966593503952, "_step": 234, "_wandb": {"runtime": 488}}