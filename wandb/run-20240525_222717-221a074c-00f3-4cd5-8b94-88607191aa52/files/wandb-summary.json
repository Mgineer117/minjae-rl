{"loss/critic_loss": 7.975601673126221, "loss/actor_loss": -6.357828929992593e-09, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 2.456247329711914, "_timestamp": 1716695374.6752558, "eval/episode_reward": 11.666666666666666, "eval/episode_reward_std": 1.247219128924647, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 11.666666666666666, "eval/episode_length_std": 1.247219128924647, "update/env_step": 335.0, "_runtime": 1336.671136856079, "_step": 335}