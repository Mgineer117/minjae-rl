[36mSaving config:
{
    "K_epochs":	5,
    "action_dim":	"1",
    "actor_hidden_dims":	[
        256,
        256
    ],
    "actor_lr":	0.0001,
    "agent_type":	"InvertedPendulum",
    "algo_name":	"ppo",
    "critic_lr":	0.0002,
    "data_num":	1000000,
    "device":	"cpu",
    "env_type":	"Gym",
    "episode_len":	1000,
    "episode_num":	2,
    "epoch":	100,
    "eps_clip":	0.2,
    "eval_episodes":	3,
    "group":	"Gym-InvertedPendulum-seed-0",
    "hidden_dims":	[
        256,
        256
    ],
    "import_policy":	false,
    "logdir":	"log/ppo-4d4c-seed0/Gym-InvertedPendulum-seed-0",
    "max_action":	"3.0",
    "name":	"ppo-4d4c-seed0",
    "obs_shape":	[
        4
    ],
    "project":	"data-collect",
    "rendering":	true,
    "seed":	0,
    "step_per_epoch":	10,
    "task":	"Gym-InvertedPendulum",
    "task_name":	null,
    "task_num":	1,
    "verbose":	true
}
Epoch:   0%|                                                                                         | 0/100 [00:00<?, ?it/s]








  gym.logger.warn(
Epoch:   1%|â–Š                                                                                | 1/100 [00:19<31:40, 19.20s/it]

































































































































































































































Traceback (most recent call last):
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data/ppo_collect.py", line 153, in <module>
    train()
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data/ppo_collect.py", line 149, in train
    policy_trainer.online_train(args.seed)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/../minjae-rl/rlkit/policy_trainer/mf_policy_trainer.py", line 138, in online_train
    loss = self.policy.learn(batch); loss['sample_time'] = sample_time
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/../minjae-rl/rlkit/policy/model_free/ppo.py", line 198, in learn
    loss.backward()
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt