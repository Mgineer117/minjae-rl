Epoch:   0%|                                                                               | 0/100 [00:00<?, ?it/s]
Training:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                | 3/10 [00:01<00:04,  1.62it/s]
[36mSaving config:
{
    "K_epochs":	5,
    "action_dim":	"1",
    "actor_hidden_dims":	[
        256,
        256
    ],
    "actor_lr":	0.0001,
    "agent_type":	"InvertedPendulum",
    "algo_name":	"ppo",
    "critic_lr":	0.001,
    "data_num":	1000000,
    "device":	"cpu",
    "env_type":	"Gym",
    "episode_len":	500,
    "episode_num":	2,
    "epoch":	100,
    "eps_clip":	0.2,
    "eval_episodes":	3,
    "group":	"Gym-InvertedPendulum-seed-0",
    "hidden_dims":	[
        256,
        256
    ],
    "import_policy":	false,
    "logdir":	"log/ppo-478d-seed0/Gym-InvertedPendulum-seed-0",
    "max_action":	"3.0",
    "name":	"ppo-478d-seed0",
    "obs_shape":	[
        4
    ],
    "project":	"osrl-test",
    "rendering":	false,
    "seed":	0,
    "step_per_epoch":	10,
    "task":	"Gym-InvertedPendulum",
    "task_name":	null,
    "task_num":	1,
    "verbose":	true
}


  gym.logger.warn(
Epoch:   1%|â–‹                                                                      | 1/100 [00:07<12:18,  7.46s/it]




Traceback (most recent call last):
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data.py", line 153, in <module>
    train()
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data.py", line 149, in train
    policy_trainer.online_train(args.seed)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/rlkit/policy_trainer/mf_policy_trainer.py", line 137, in online_train
    batch, sample_time = self.sampler.collect_samples(self.policy, seed)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/rlkit/buffer/sampler.py", line 288, in collect_samples
    policy = self.to_device(policy, self.device)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/rlkit/buffer/sampler.py", line 233, in to_device
    policy = policy.to(device)
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1173, in to
    return self._apply(convert)
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 804, in _apply
    param_applied = fn(param)
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1159, in convert
    return t.to(
KeyboardInterrupt