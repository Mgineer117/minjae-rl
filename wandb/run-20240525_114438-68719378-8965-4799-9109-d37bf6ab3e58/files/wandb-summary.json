{"loss/critic_loss": 6.919185519218445, "loss/actor_loss": 3.444750726222992, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 0.4244573712348938, "_timestamp": 1716655497.3071783, "_runtime": 18.926375150680542, "_step": 23, "eval/episode_reward": 13.333333333333334, "eval/episode_reward_std": 0.9428090415820634, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 13.333333333333334, "eval/episode_length_std": 0.9428090415820634, "update/env_step": 19.0, "_wandb": {"runtime": 18}}