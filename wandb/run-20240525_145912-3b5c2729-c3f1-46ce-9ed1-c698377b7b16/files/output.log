[36mSaving config:
{
    "action_dim":	"3",
    "actor_hidden_dims":	[
        256,
        256
    ],
    "agent_type":	"Hopper",
    "algo_name":	"trpo",
    "critic_lr":	0.0001,
    "data_num":	1000000,
    "device":	"cpu",
    "env_type":	"Gym",
    "episode_len":	1000,
    "episode_num":	2,
    "epoch":	2000,
    "eval_episodes":	3,
    "group":	"Gym-Hopper-seed-0",
    "hidden_dims":	[
        256,
        256
    ],
    "import_policy":	false,
    "logdir":	"log/trpo-914e-seed0/Gym-Hopper-seed-0",
    "max_action":	"1.0",
    "name":	"trpo-914e-seed0",
    "obs_shape":	[
        11
    ],
    "pklfile":	null,
    "project":	"data-collect",
    "rendering":	false,
    "seed":	0,
    "step_per_epoch":	10,
    "task":	"Gym-Hopper",
    "task_name":	null,
    "task_num":	3,
    "verbose":	true
}
Epoch:   0%|                                                                                 | 0/2000 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data/trpo_collect.py", line 147, in <module>
    train()
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data/trpo_collect.py", line 143, in train
    policy_trainer.online_train(args.seed)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/../minjae-rl/rlkit/policy_trainer/mf_policy_trainer.py", line 138, in online_train
    loss = self.policy.learn(batch); loss['sample_time'] = sample_time
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/../minjae-rl/rlkit/policy/model_free/trpo.py", line 237, in learn
    if self.gard_norm:
  File "/home/minjae/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'TRPOPolicy' object has no attribute 'gard_norm'