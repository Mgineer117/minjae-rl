{"loss/critic_loss": 5.036365836858749, "loss/actor_loss": 2.5020911693573002, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 1.5890947580337524, "_timestamp": 1716695373.5869696, "_runtime": 756.882378578186, "_step": 187, "eval/episode_reward": 10.0, "eval/episode_reward_std": 1.4142135623730951, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 10.0, "eval/episode_length_std": 1.4142135623730951, "update/env_step": 179.0}