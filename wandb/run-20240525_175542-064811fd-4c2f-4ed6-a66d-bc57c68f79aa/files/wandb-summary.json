{"loss/critic_loss": 1065514.875, "loss/actor_loss": -1.7619133529933606e-07, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 1.9672584533691406, "_timestamp": 1716677757.0316906, "eval/episode_reward": 61.333333333333336, "eval/episode_reward_std": 10.842303978193728, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 61.333333333333336, "eval/episode_length_std": 10.842303978193728, "update/env_step": 0.0, "_runtime": 14.42302656173706, "_step": 0}