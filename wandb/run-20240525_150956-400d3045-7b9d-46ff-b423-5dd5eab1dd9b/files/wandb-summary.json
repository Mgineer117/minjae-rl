{"loss/critic_loss": 65.62318420410156, "loss/actor_loss": 1.0347365986262957e-07, "train/stochastic_reward": 0.8377470970153809, "train/success": 0.0, "sample_time": 1.3905556201934814, "_timestamp": 1716668306.3453217, "_runtime": 510.0777516365051, "_step": 220, "eval/episode_reward": 8.715325337517262, "eval/episode_reward_std": 5.533046747659321, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 32.0, "eval/episode_length_std": 5.0990195135927845, "update/env_step": 219.0, "_wandb": {"runtime": 509}}