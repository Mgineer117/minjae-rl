[36mSaving config:
{
    "K_epochs":	10,
    "action_dim":	"1",
    "actor_hidden_dims":	[
        256,
        256
    ],
    "actor_lr":	0.0001,
    "agent_type":	"InvertedPendulum",
    "algo_name":	"ppo",
    "critic_lr":	0.003,
    "data_num":	1000000,
    "device":	"cpu",
    "env_type":	"Gym",
    "episode_len":	1000,
    "episode_num":	2,
    "epoch":	100,
    "eps_clip":	0.2,
    "eval_episodes":	3,
    "group":	"Gym-InvertedPendulum-seed-0",
    "hidden_dims":	[
        256,
        256
    ],
    "import_policy":	false,
    "logdir":	"log/ppo-8cf3-seed0/Gym-InvertedPendulum-seed-0",
    "max_action":	"3.0",
    "name":	"ppo-8cf3-seed0",
    "obs_shape":	[
        4
    ],
    "project":	"osrl-test",
    "rendering":	true,
    "seed":	0,
    "step_per_epoch":	50,
    "task":	"Gym-InvertedPendulum",
    "task_name":	null,
    "task_num":	1,
    "verbose":	true
}
Epoch:   0%|                                                                               | 0/100 [00:00<?, ?it/s]















































  gym.logger.warn(
Epoch:   1%|â–‹                                                                   | 1/100 [01:46<2:55:06, 106.13s/it]







































































































Traceback (most recent call last):
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data.py", line 153, in <module>
    train()
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/collect_data.py", line 149, in train
    policy_trainer.online_train(args.seed)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/rlkit/policy_trainer/mf_policy_trainer.py", line 138, in online_train
    loss = self.policy.learn(batch); loss['sample_time'] = sample_time
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/rlkit/policy/model_free/ppo.py", line 158, in learn
    advantages, returns = estimate_advantages(rewards, masks, r_pred.detach(), self._gamma, self._tau, self.device)
  File "/home/minjae/Documents/Minjae/Research/minjae-rl/rlkit/utils/utils.py", line 71, in estimate_advantages
    prev_advantage = advantages[i, 0]
KeyboardInterrupt