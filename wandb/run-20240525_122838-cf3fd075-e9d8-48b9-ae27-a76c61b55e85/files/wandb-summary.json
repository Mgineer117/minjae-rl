{"loss/critic_loss": 2.786548058191935, "loss/actor_loss": 1.3608919580777485, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 0.9416203498840332, "_timestamp": 1716658453.6857922, "_runtime": 335.56697821617126, "_step": 155, "eval/episode_reward": 11.0, "eval/episode_reward_std": 0.0, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 11.0, "eval/episode_length_std": 0.0, "update/env_step": 149.0, "_wandb": {"runtime": 336}}