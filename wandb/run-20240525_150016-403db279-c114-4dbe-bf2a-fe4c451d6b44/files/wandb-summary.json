{"loss/critic_loss": 59.81708971659342, "loss/actor_loss": 5.3147473237184314e-08, "train/stochastic_reward": 0.8212138116359711, "train/success": 0.0, "sample_time": 1.618248701095581, "_timestamp": 1716671372.1939535, "_runtime": 4155.225256443024, "_step": 1705, "eval/episode_reward": 90.57184331933733, "eval/episode_reward_std": 77.3618613256249, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 84.66666666666667, "eval/episode_length_std": 59.60611452601896, "update/env_step": 1699.0, "_wandb": {"runtime": 4155}}