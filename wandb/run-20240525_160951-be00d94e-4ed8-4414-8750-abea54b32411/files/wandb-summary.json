{"loss/critic_loss": NaN, "loss/actor_loss": -7.96318082585401e-08, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 1.164976418018341, "_timestamp": 1716671914.3540208, "_runtime": 522.6706438064575, "_step": 203, "eval/episode_reward": 15.333333333333334, "eval/episode_reward_std": 4.189935029992179, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 15.333333333333334, "eval/episode_length_std": 4.189935029992179, "update/env_step": 199.0, "_wandb": {"runtime": 524}}