{"loss/critic_loss": 1.018100998618386, "loss/actor_loss": 0.47312999584458093, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 0.5326238328760321, "_timestamp": 1716656947.9782233, "_runtime": 1153.5297112464905, "_step": 1460, "eval/episode_reward": 3.0, "eval/episode_reward_std": 0.0, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 3.0, "eval/episode_length_std": 0.0, "update/env_step": 1449.0, "_wandb": {"runtime": 1153}}