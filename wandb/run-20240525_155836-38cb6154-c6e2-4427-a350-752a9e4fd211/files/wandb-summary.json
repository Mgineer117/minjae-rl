{"loss/critic_loss": 3.712560755865914, "loss/actor_loss": 1.7996148211615426, "train/stochastic_reward": 0.7376211711338588, "train/success": 0.0, "sample_time": 1.5965805053710938, "_timestamp": 1716671547.226292, "_runtime": 831.220705986023, "_step": 316, "eval/episode_reward": 8.894026103342334, "eval/episode_reward_std": 0.8434806534308055, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 10.333333333333334, "eval/episode_length_std": 0.4714045207910317, "update/env_step": 309.0, "_wandb": {"runtime": 831}}