{"loss/critic_loss": 4.760318994522095, "loss/actor_loss": 2.364838620026906, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 1.4351085821787517, "_timestamp": 1716694578.8141854, "_runtime": 270.73149943351746, "_step": 75, "eval/episode_reward": 10.0, "eval/episode_reward_std": 2.160246899469287, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 10.0, "eval/episode_length_std": 2.160246899469287, "update/env_step": 69.0, "_wandb": {"runtime": 271}}