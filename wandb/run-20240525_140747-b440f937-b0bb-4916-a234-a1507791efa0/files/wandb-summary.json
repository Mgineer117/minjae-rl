{"loss/critic_loss": 29.369305697354402, "loss/actor_loss": -9.531324578078553e-09, "train/stochastic_reward": 0.8930218490687284, "train/success": 0.0, "sample_time": 1.2446393749930644, "_timestamp": 1716664903.9870768, "_runtime": 836.6061487197876, "_step": 510, "eval/episode_reward": 5.180066921257898, "eval/episode_reward_std": 3.5708934103775762, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 9.666666666666666, "eval/episode_length_std": 4.496912521077347, "update/env_step": 499.0, "_wandb": {"runtime": 835}}