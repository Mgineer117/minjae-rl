{"loss/critic_loss": 713099.75, "loss/actor_loss": -2.384185791015625e-07, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 1.8455696105957031, "_timestamp": 1716676129.619839, "eval/episode_reward": 80.66666666666667, "eval/episode_reward_std": 2.357022603955158, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 80.66666666666667, "eval/episode_length_std": 2.357022603955158, "update/env_step": 6.0, "_runtime": 28.556808948516846, "_step": 6}