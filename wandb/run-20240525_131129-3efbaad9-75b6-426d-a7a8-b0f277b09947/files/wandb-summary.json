{"loss/critic_loss": 0.91738583445549, "loss/actor_loss": 1.8537046342359531e-09, "train/stochastic_reward": 1.0, "train/success": 0.0, "sample_time": 0.8447743415832519, "_timestamp": 1716662168.5349677, "_runtime": 1479.4851605892181, "_step": 999, "eval/episode_reward": 3.6666666666666665, "eval/episode_reward_std": 0.4714045207910317, "eval/ep_success_mean": 0.0, "eval/ep_success_std": 0.0, "eval/episode_length": 3.6666666666666665, "eval/episode_length_std": 0.4714045207910317, "update/env_step": 999.0, "_wandb": {"runtime": 1478}}